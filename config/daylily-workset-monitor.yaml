# Example configuration for the daylily workset monitor tool.
# Copy and edit this file before running bin/daylily-monitor-worksets.

aws:
  profile: default
  region: us-east-1
  # Optional session duration for profile authentication in seconds.
  session_duration_seconds: 3600

# NOTE: The monitor does not have a default bucket. Each workset has its own bucket
# assigned during creation based on the selected cluster's region (from ~/.ursa/config.yaml).
monitor:
  prefix: daylily_monitoring/active_worksets/
  archive_prefix: daylily_monitoring/archived_worksets/
  poll_interval_seconds: 60
  ready_lock_backoff_seconds: 30
  # Set to true to keep looping forever.  When false the monitor performs one scan and exits.
  continuous: true
  max_concurrent_worksets: 1
  # Optional: Sentinel index for global state tracking
  # sentinel_index_prefix: daylily_monitoring/
  # sentinel_index_bucket: my-daylily-bucket

cluster:
  # Reuse an existing cluster when available, otherwise create from this template.
  template_path: config/cluster-configs/example.yaml
  # Contact email exported for cluster creation when not present in template overrides.
  contact_email: you@email.com
  repo_tag: main
  preferred_availability_zone: us-east-1a
  auto_teardown: false
  idle_teardown_minutes: 20
  # Optional pre-existing cluster name.  When empty a new cluster is created as required.
  reuse_cluster_name: ""

pipeline:
  # Directory on the headnode where worksets will be staged.
  workdir: /fsx/data/worksets
  # Local directory where stage_samples manifests are mirrored prior to staging commands.
  local_stage_root: .
  # Optional explicit S3 bucket URI passed to staging commands.  Defaults to the monitor bucket when omitted.
  reference_bucket: s3://my-daylily-bucket/
  # SSH identity file used when running commands on the head node.
  ssh_identity_file: ~/.ssh/daylily-headnode.pem
  # SSH user name for the head node connection.
  ssh_user: ubuntu
  # Additional SSH/SCP options when connecting to the head node.
  ssh_extra_args: []
  # Command that prepares staging files on the headnode.
  # Available variables: {profile}, {region}, {reference_bucket}, {analysis_samples}, {output_dir}
  # Note: --config-dir ensures generated samples.tsv/units.tsv are written to the workset state dir
  stage_command: ./bin/daylily-stage-samples-from-local-to-headnode --profile {profile} --region {region} --reference-bucket {reference_bucket} --config-dir {output_dir} {analysis_samples}
  # Command that creates the pipeline working tree before execution.  The day-clone output
  # is parsed to determine the working directory for subsequent commands.
  clone_command: echo cloning && day-clone {clone_args}
  # Command prefix that initialises the analysis environment.  The dy-r suffix from the workset yaml
  # is appended to the end of this string.
  run_prefix: "source dyoainit && source bin/day_activate slurm hg38  && DAY_CONTAINERIZED=0 ./bin/day_run "
  # Maximum time (in minutes) to wait for the pipeline success sentinel before aborting.
  pipeline_timeout_minutes: 240
  # Command that exports results back to S3 after completion.  The template may
  # reference {cluster}, {target_uri}, {region}, {profile}, {output_dir},
  # {workdir_name}, {workset_dir}, {pipeline_dir}, and {workset}.
  # IMPORTANT: {output_dir} must be used for --output-dir to match where monitor looks for fsx_export.yaml
  export_command: ./bin/daylily-export-fsx-to-s3-from-local --cluster {cluster} --target-uri analysis_results/ubuntu/{workdir_name} --region {region} --profile {profile} --output-dir {output_dir} --verbose
  # Command executed before entering the pipeline directory on the head node.
  login_shell_init: echo Ready2run 
  # Prefix used when generating tmux session names for launched pipelines.
  tmux_session_prefix: daylily
  # Shell invoked at the end of the tmux command to keep the session alive for inspection.
  tmux_keepalive_shell: bash


# optional if you want the monitor to fetch your repo/branch on the headnode
day-clone: "--repo Daylily-Informatics/daylily-omics-analysis --branch main"

# required: appended to run_prefix
dy-r: "--name runme14 --samples config/samples.tsv --outdir results/runme14 --profile slurm --jobs 192 --rerun-incomplete"

# optional export
export_uri: "s3://my-daylily-bucket/daylily_monitoring/active_worksets/runme14/results/"

